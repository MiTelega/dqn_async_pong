{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "077f6ce1",
   "metadata": {},
   "source": [
    "Гиперпараметры:\n",
    "\n",
    "Total Timesteps: 2_500_000\n",
    "Learning Rate: 0.0001\n",
    "Buffer Size: 1_000_000\n",
    "Batch Size: 32\n",
    "Gamma: 0.99\n",
    "Sync Frequences: 1|5|10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151cfe3b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(filename='reward_vs_steps.png'))\n",
    "display(Image(filename='reward_vs_time.png'))\n",
    "display(Image(filename='reward_vs_updates.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a1ac0c",
   "metadata": {},
   "source": [
    "Итоги сравнения графиков на разных частотах синхронизации:\n",
    "\n",
    "Для большей частоты синхронизации freq = 10 дисперсия действительно меньше, особенно на начальных этапах, поскольку частое подтягивание весов нейросети не дает\n",
    "нам набрать опыта и предсказываемая Q функция гоняется за своим хвостом, однако разница в дисперсии не очень сильная и сходимость у более агрессивных тактик freq = 1 и freq = 5 идёт быстрее,\n",
    "разницу в дисперсии гасит стохастика и то что ошибки акторов друг друга компенсируют, что-то похожее на bagging, отсюда и при более частых обновлениях, которые друг друга уравновешивают,\n",
    "лучше сходимость.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
